---
title: "CS109b-hw4-submission"
author: "Ihsaan Patel"
date: "March 4, 2017"
output: pdf_document
---

# Libraries

```{r libraries, message=FALSE}
library(e1071)
library(caret)
library(mclust)
```

# Problem 1: Celestial Object Classification

## Load Data

```{r load_data}
# Load training set
dataset_1_train <- read.table("datasets/dataset_1_train.txt", header = TRUE, sep = ",")
dataset_1_train$Class <- as.factor(dataset_1_train$Class)

# Load testing set
dataset_1_test <- read.table("datasets/dataset_1_test.txt", header = TRUE, sep = ",")
dataset_1_test$Class <- as.factor(dataset_1_test$Class)
```

## 1. RBF Kernel: Gamma = 1, Cost = 1

```{r rbf_g1_c1}
# Fit SVM
model.svm_rbf_g1_c1 <- svm(Class ~ ., data = dataset_1_train, cost = 1, gamma = 1, kernel = "radial")

# Predict Test Set and Calculate Accuracy
pred.svm_rbf_g1_c1 <- predict(model.svm_rbf_g1_c1, dataset_1_test)
table.svm_rbf_g1_c1 <- table(pred.svm_rbf_g1_c1, dataset_1_test$Class)
accuracy.svm_rbf_g1_c1 <- sum(diag(table.svm_rbf_g1_c1))/ sum(table.svm_rbf_g1_c1)
print(sprintf("SVM Class = 1 Gamma = 1 Model Test Accuracy: %.4f", accuracy.svm_rbf_g1_c1))
```

## 2. Confusion Matrix

### Train Confusion Matrix
```{r train_confusion_matrix}
# Print Train Confusion Matrix
confusionMatrix(table(predict(model.svm_rbf_g1_c1, dataset_1_train), dataset_1_train$Class))
```

### Test Confusion Matrix

```{r test_confusion_matrix}
# Print Test Confusion Matrix
confusionMatrix(table(predict(model.svm_rbf_g1_c1, dataset_1_test), dataset_1_test$Class))
```

The model appears to overfit the training set by correctly predicting the class for every observation, while for the testing set the model just predicts class 3 for every observation.

## 3. Tuning Gamma

```{r tune_gamma}
# Initiate list with gammas and lists to store error rates
gammas <- c(0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3)
gamma_train_scores <- rep(0., length(gammas))
gamma_test_scores <- rep(0., length(gammas))

# Loop through each gamma value, fitting an svm and calculating training and test error artes
for (gamma in 1:length(gammas)) {
  model.svm_tune_gamma <- svm(Class ~ ., data = dataset_1_train, cost = 1, gamma = gammas[gamma], kernel = "radial")
  gamma_train_scores[gamma] <- classError(predict(model.svm_tune_gamma, dataset_1_train), dataset_1_train$Class)$errorRate
  gamma_test_scores[gamma] <- classError(predict(model.svm_tune_gamma, dataset_1_test), dataset_1_test$Class)$errorRate
}

# Plot training and test error rates
gamma_scores <- data.frame(gammas = gammas, train_scores = gamma_train_scores, test_scores = gamma_test_scores)
ggplot(gamma_scores, aes(gammas)) + geom_line(aes(y = train_scores, colour = "Train Error Rate")) + geom_line(aes(y = test_scores, colour = "Test Error Rate")) + ylab("Error Rate") + xlab("Gamma Value") + ggtitle("SVM Error Rate by Gamma Parameter")
```

It looks like model performance on the test set improves at very low levels as gamma increases (until gamma = 0.01) but then deteriorates rapidly as gamma continues to increase. The train error rate continues to improve as gamma increases, indicating clear overfiting post gamma = 0.01.

## 4. Tuning Class

```{r tune_class}
# Initiate list with costs and lists to store error rates
costs <- c(0.1, 0.25, 0.5, 0.75, 1., 2.5, 5., 7.5, 10., 12.5, 15., 17.5, 20.)
cost_train_scores <- rep(0., length(costs))
cost_test_scores <- rep(0., length(costs))

# Loop through each cost value, fitting an svm and calculating training and test error artes
for (cost in 1:length(costs)) {
  model.svm_tune_cost <- svm(Class ~ ., data = dataset_1_train, cost = costs[cost], gamma = 0.01, kernel = "radial")
  cost_train_scores[cost] <- classError(predict(model.svm_tune_cost, dataset_1_train), dataset_1_train$Class)$errorRate
  cost_test_scores[cost] <- classError(predict(model.svm_tune_cost, dataset_1_test), dataset_1_test$Class)$errorRate
}

# Plot training and test error rates
cost_scores <- data.frame(costs = costs, train_scores = cost_train_scores, test_scores = cost_test_scores)
ggplot(cost_scores, aes(costs)) + geom_line(aes(y = train_scores, colour = "Train Error Rate")) + geom_line(aes(y = test_scores, colour = "Test Error Rate")) + ylab("Error Rate") + xlab("Cost Value") + ggtitle("SVM Error Rate by Cost Parameter")
```

It looks like model performance on the test set improves at low levels as cost increases (until cost = 2.5) but then deteriorates slowly as cost continues to increase. The train error rate continues to improve as cost increases, indicating clear overfiting post cost = 2.5.

